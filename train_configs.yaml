train:
  max_epoch: 20
  image_interval: 5
  board_interval: 5
  learning_rate: !!float 5e-4
  val_interval: 1
  save_interval: 2
  checkpoint_dir: 'checkpoints'
  image_dir: 'images'
  base_dir: 'ffhq_results/ffclip'
  txt_path: 'loss.txt'
  gradient_clipping: 5
  lr_steps_rel: [0.5, 0.75, 0.9, 0.95]
  lr_gamma: 0.5
  disc_start: 5
data:
  batch_size: 8
  train_latents: 'datasets/Celeba_HQ/train_latents.npy'
  test_latents: 'datasets/Celeba_HQ/test_latents.npy' 
#   emo_prob: 0.25
#   age_gender_prob: 0.15
#   hair_color_prob: 0.05
#   eyes_prob: 0.05
#   face_prob: 0.2
#   hair_style_prob: 0.3

data_type: 'ffhq' 

loss:
  id_lambda: 0.9
  clip_lambda: 1.0
  x_l2_lambda: 0.0
  latent_lambda: 1.6
  discrim_lambda: 0
  bgloss_lambda: 2.0
  embd_lambda: 1.0


generator:
  style_dim: 512
  n_mlp: 8
  size: 1024 #256
  channel_multiplier: 2
  blur_kernel: [ 1, 3, 3, 1 ]
  lr_mlp: 0.01

pretrain_path: 'pretrained_models/stylegan2-ffhq-config-f.pt'
e4e_path: 'pretrained_models/e4e_ffhq_encode.pt'
clip_path: 'pretrained_models/ViT-B-32.pt'
ID_path: 'pretrained_models/model_ir_se50.pth'
parsenet_weights: 'pretrained_models/parsenet.pth'

resume: 
  pretrain: True
  resume_dir: 'ffhq_results/ffclip/checkpoints/resume.pt'
  result_dir: 'ffhq_results/ffclip'
